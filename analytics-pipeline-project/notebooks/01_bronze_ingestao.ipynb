{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abdc0b11-6304-43cd-aca0-0d35dc24f2dd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Reading the database"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pyspark.sql.types\n",
    "from pyspark.sql import functions \n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "file_path = \"/Volumes/workspace/default/data-volume/1970-2021_DISASTERS.xlsx - emdat data.csv\"\n",
    "\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21835b43-2f61-408a-b3a3-569c7b6ad2bd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Defining a schema"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE SCHEMA IF NOT EXISTS bronze;\n",
    "CREATE SCHEMA IF NOT EXISTS silver;\n",
    "CREATE SCHEMA IF NOT EXISTS gold;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "6b72e26c-105e-484f-8869-06e2b6bad3dc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Checking table structure and data"
    }
   },
   "outputs": [],
   "source": [
    "display(df.limit(10))\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "# Colunas que devem ser observadas: Dis No, Seq, ISO, Associated Dis, Associated Dis2, Dis Mag Value, Dis Mag Scale, Reconstruction Costs ('000 US$), Insured Damages ('000 US$),\n",
    "# #Total Damages ('000 US$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d158133-eba2-4d1e-97a9-c91c5489ad5a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Adjusting column names with spaces and symbols with a function"
    }
   },
   "outputs": [],
   "source": [
    "#criando uma função para limpar os nomes das colunas\n",
    "def clean_column(col_name):\n",
    "    col_name = col_name.lower()                                         #transforma em minusculas\n",
    "    col_name = col_name.replace(\" \", \"_\").replace(\"-\", \"_\")             #remove espaços e traços por underscore                                    \n",
    "    col_name = re.sub(r\"[ ,;{}()\\n\\t=]\", \"_\", col_name)                 # troca caracteres problemáticos por _\n",
    "    col_name = re.sub(r\"[^0-9a-zA-Z_]\", \"\", col_name)                   # remove qualquer outro caractere especial\n",
    "    col_name = re.sub(r\"_+\", \"_\", col_name)                             # colapsa underscores duplos\n",
    "    col_name = col_name.strip(\"_\")                                      # remove _ no início/fim\n",
    "    \n",
    "    return col_name\n",
    "                                          \n",
    "df = df.toDF(*[clean_column(c) for c in df.columns])        # aplica a função em todas as colunas do dataframe, percorrendo com o loop for\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fcad60e-b7d6-49ca-ac63-33dae7513920",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Creating a schema"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE CATALOG IF NOT EXISTS analytics;\n",
    "CREATE SCHEMA IF NOT EXISTS bronze;\n",
    "CREATE SCHEMA IF NOT EXISTS silver;\n",
    "CREATE SCHEMA IF NOT EXISTS gold;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c44a8e8-babf-4ebc-8302-5585f98ab743",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Saving df as Delta and partitioning"
    }
   },
   "outputs": [],
   "source": [
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"bronze.bronze_disasters\")\n",
    "\n",
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "8d9bc90f-5a0b-43d1-9539-6fce00fb4735",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Checking if it worked and the DataFrame turned into Delta Table"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "DESCRIBE DETAIL `bronze_disasters`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13811ca1-31e7-4f00-8780-5ddc67752570",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS bronze_disasters\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7320551621068350,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01_bronze_ingestao",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
